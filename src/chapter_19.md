# 第19章 微调介绍
# 主要内容
- 学习如何通过一些方法来提高现有模型在特定用例中的性能。
- 了解一些用来评估你微调后的LLM的性能的指标，并量化其相对于初始基础模型的改进。

# 背景：
- 针对较小的LLM，即使提供一个或多个示例（称为单样本或少样本推理），也不总是有效。
- 提示中包含的任何示例都会占用上下文窗口中的宝贵空间，减少你包含其他有用信息的空间。
- 利用一种称为微调（fine-tuning）的过程来进一步训练基础模型

# 微调
## 概念
与预训练不同，预训练是通过自监督学习使用大量非结构化文本数据来训练LLM，而微调是一种监督学习过程，使用带有标签示例的数据集来更新LLM的权重。这些标签示例是提示-完成对，微调过程通过扩展模型的训练来提高其在特定任务中生成良好完成结果的能力。

## 指令微调
- 指令微调通过使用示例来训练模型，这些示例（提示-完成对），使模型能够学会生成遵循给定指令的响应。
- 提高摘要生成能力，可以构建一个以“总结以下文本”或类似短语开头的示例数据集。
- 提高模型的翻译能力，示例将包含诸如“翻译此句子”之类的指令。
- 指令微调更新了模型的所有权重，称为全微调。这个过程会生成一个具有更新权重的新版本模型。需要足够的内存和算力资源，可以使用内存优化和并行计算策略。

## 如何进行LLM指令微调
1. 准备训练数据。
有许多公开可用的数据集曾用于训练早期版本的语言模型，尽管其中大多数数据集并未以指令形式格式化。幸运的是，开发人员已经组装了提示模板库，这些库可以用于将现有数据集（例如亚马逊产品评论的大型数据集）转换为用于微调的指令提示数据集。提示模板库包含许多针对不同任务和数据集的模板。以下是三个设计用于亚马逊评论数据集的提示，可用于微调模型以进行分类、文本生成和文本摘要任务。

你可以看到，在每种情况下，你将原始评论（此处称为review_body）传递给模板，模板将其插入到以指令开头的文本中，例如“预测相关评分”、“生成星级评论”或“用一句话描述以下产品评论”。结果是一个现在包含指令和数据集示例的提示。

2. 选择训练集提示及生成结果
一旦你准备好指令数据集，就像标准的监督学习一样，你将数据集分为训练集、验证集和测试集。在微调过程中，你从训练数据集中选择提示并将其传递给LLM，LLM随后生成完成结果。

3. 结果比对及更新模型权重
接下来，你将LLM的完成结果与训练数据中指定的响应进行比较。LLM的输出是跨标记的概率分布。因此，可以比较完成结果的分布和训练标签的分布，并使用标准的交叉熵函数来计算两个标记分布之间的损失。然后使用计算出的损失在标准反向传播中更新模型权重。你将针对许多批次的提示-完成对执行此操作，并更新权重，以提高模型在任务上的性能。

4. 评估
完成微调后，使用保留的测试数据集进行最终的性能评估。这将为你提供测试准确率。微调过程会生成一个新版本的基础模型，通常称为指令模型，它在您感兴趣的任务上表现更好。

## 总结
指令提示进行微调是微调LLM的最常见方式。当看到“微调”这个术语时，你可以假设它总是指指令微调。
