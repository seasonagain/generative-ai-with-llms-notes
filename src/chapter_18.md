# 第18章 Week2导语
## 背景
- 当你拥有一个基础模型，也就是最初经过预训练的模型时，它编码了很多非常有用的信息，通常是关于世界的知识。从互联网和其他来源的通用文本中学习，模型学会了预测下一个单词。
- 预测互联网上下一个单词和遵循指令可不是一回事，当我们指示它执行某项特定任务时，它不一定知道如何回应我们的提示和问题。
- 微调是一种在预训练模型的基础上进行的训练方法，它可以帮助模型更好地适应特定的任务和领域。

## 指令微调
### 概念
- 用互联网上数以千亿计的单词对大型语言模型进行训练，然后用一个小得多的数据集对其进行关于遵循指令方面的微调，它就能学会这么做。
- 指令微调能帮助它改变自身行为，使其对我们更有帮助。
- 指令微调是大型语言模型发展历程中的重大突破之一。

### 存在问题
- 灾难性遗忘：在这种指令微调过程中，你用一些额外的数据对模型进行训练，然后它就会忘记之前学到的所有东西，或者很大一部分之前的数据。
- 解决方式：在非常广泛的不同指令类型上进行指令微调，不只是针对你希望它做的事情进行微调，需要把范围放得更广一些。

### 参数微调
1. 全量微调（Full Fine-Tuning）
- 计算和内存方面的开销都非常大：使用一个大型模型，并对该模型中的每一个参数进行微调，需要存储并部署这个庞大的模型，成本过高。
2. 参数高效微调 （Parameter-Efficient Fine-Tuning, PEFT）
- 与全量微调相似的性能效果：参数高效微调在很多任务上，它仍然能够达到与全量微调类似的性能效果。通过冻结原始模型的权重，或者在原始模型之上添加自适应层，这样内存占用就会小得多，就可以针对多个任务进行训练。
- 极大降低成本：全量微调的成本非常高。参数高效微调（PEFT）这样的技术，让普通用户也能对生成式人工智能模型进行微调。
- 低秩适应（LoRA） (Low-Rank Adaptation)：以最小的计算和内存需求获得非常好的性能表现。很多开发者通常会从提示工程入手，有时候这能带来足够好的性能。但有时候提示工程的性能会遇到瓶颈，这时像 LoRA 或其他PEFT技术对于提升到更高的性能水平就非常关键。