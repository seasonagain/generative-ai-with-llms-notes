# 第22章 FLAN: Fine-tuned Language Net

## 概述
- **方法**: FLAN 是一种指令微调方法。
- **模型**: 基于 540B 的 PaLM 模型进行微调。
- **任务数量**: 1836 个任务。
- **关键改进**: 结合 Chain-of-Thought Reasoning 数据，提升泛化能力、人类可用性和零样本推理能力。

## 任务与数据集
- 任务扩展:
  - 引入 Muffin 的对话和程序合成任务。
  - 结合新的 Chain-of-Thought Reasoning 任务。
  - 包含 T0 和 Natural Instructions v2 等任务集合的子集。
- 评估方式**:
  - 部分任务在训练期间被保留，用于评估模型在未见任务上的表现，保留任务（Held - out tasks）
- 微调任务（Finetuning tasks）
    - TO-SF：包含常识推理、问题生成、闭卷问答、对抗性问答、抽取式问答、标题 / 上下文生成、主题分类、结构到文本等任务，涉及 55 个数据集、14 个类别、193 项任务。
    - Muffin：涵盖自然语言推理、代码指令生成、程序合成、对话上下文生成、闭卷问答、对话问答、代码修复等任务，有 69 个数据集、27 个类别、80 项任务。
    - CoT (Reasoning)：即思维链推理，包括算术推理、常识推理、隐含推理、解释生成、句子组合等任务，涉及 9 个数据集、1 个类别、9 项任务。
    - Natural Instructions v2：包含因果关系分类、常识推理、命名实体识别、有毒语言检测、问答、问题生成、程序执行、文本分类等任务，涉及 372 个数据集、108 个类别、1554 项任务。
    - 数据集是原始数据源（如 SQuAD）。
    - 任务类别是独特的任务设置（如 SQuAD 数据集可配置用于多种任务类别）。
    - 任务是唯一的 <数据集，任务类别> 对，有任意数量保留任务类别的模板（如 SQuAD 数据集上的查询生成任务）。
- 保留任务（Held-out tasks）
    - MMLU：涵盖多个领域的任务，如抽象代数、社会学、大学医学、哲学、专业法律等，总共 57 项任务。MMLU（Massive Multitask Language Understanding）是用于评估语言模型在多领域知识理解能力的基准。
    - BBH：包含布尔表达式、跟踪打乱对象、Dyck 语言、导航、单词排序等任务，共 27 项。它可能用于评估模型在特定逻辑和认知任务上的表现。
    - TyDiQA：是一个信息检索问答（Information seeking QA）数据集，涉及 8 种语言。它旨在测试模型在多种语言环境下处理问答任务的能力。
    - MGSM：主要是小学数学问题，涉及 10 种语言，用于评估模型在多语言环境下解决数学问题的能力 。

## 参考论文
https://arxiv.org/abs/2210.11416